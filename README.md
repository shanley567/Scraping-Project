# ğŸ“° Scraping Project

A Pythonâ€‘based Selenium automation project that extracts section headings from the BBC homepage.

This version includes  **dynamic userâ€‘agent generation** , humanâ€‘like browser behaviour, and a clean foundation for future expansion into a full newsâ€‘analysis toolkit.

## ğŸš€ Project Overview

This project launches a real Chrome browser using Selenium, navigates to the BBC homepage, and collects all visible heading elements (`h1`â€“`h6`).

Itâ€™s designed as the first step in a larger portfolio project that will grow into a structured, modular scraping and analysis system.

Current capabilities include:

* Automated Chrome session using Selenium
* Dynamic userâ€‘agent generation on each run
* Humanâ€‘like behaviour (scrolling, randomised delays, explicit waits)
* Clean extraction of all heading tags
* Fully isolated Python environment using `venv`

## ğŸ§± Features

âœ” Dynamic Userâ€‘Agent Generation

Each run generates a realistic Chrome user agent with a random version number, improving compatibility and mimicking natural browser diversity.

âœ” Humanâ€‘Like Interaction

The script scrolls, waits, and pauses in a natural way to reduce false positives and improve stability.

âœ” Modular, Expandable Design

The project is intentionally simple but structured so it can evolve into:

* A multiâ€‘page scraper
* A newsâ€‘analysis pipeline
* A scheduled cloud function
* A Dockerised microservice
* A Streamlit dashboard

## ğŸ› ï¸ Installation & Setup

### * Clone the repository

git clone https://github.com/yourusername/bbc-headline-scraper.git
cd bbc-headline-scraper

```powershell
git clone https://github.com/yourusername/bbc-headline-scraper.git
cd bbc-headline-scraper
```

2. Create a virtual environment

```powershell
python -m venv venv
```

Activate the virtual environment (PowerShell)

```powershell
.\venv\Scripts\Activate.ps1
```

.\venv\Scripts\Activate.ps1

To deactivate:

```powershell
deactivate
```

deactivate

4. Install dependencies

```powershell
pip install -r requirements.txt
```

pip install -r requirements.txt

### ğŸ§© Chrome WebDriver Setup

This project uses  **webdriverâ€‘manager** , which automatically downloads and manages the correct ChromeDriver version.

No manual installation required.

### â–¶ï¸ Running the Scraper

```powershell
python scraper.py
```

Youâ€™ll see output similar to:

Using User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...
BBC Homepage Headings:

- News
- Sport
- Business
- Technology
  ...

### ğŸ“ Project Structure

bbc_scraper/
â”‚
â”œâ”€â”€ scraper.py          # Main Selenium script with dynamic UA generation
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # Project documentation

## Future versions may introduce:

scraper/
â”‚   browser.py
â”‚   extract.py
â”‚   storage.py
â”‚   analysis/
â”‚   utils/
docker/
tests/

### ğŸ”® Roadmap

Planned enhancements include:

* Save scraped data to JSON/CSV
* Extract article URLs, summaries, timestamps
* Add structured logging
* Build a CLI interface
* Add retry logic and error handling
* Containerise with Docker
* Schedule scraping jobs (cron or cloud functions)
* Add NLP analysis (sentiment, topic modelling)
* Build a Streamlit dashboard for visualisation

### ğŸ§‘â€ğŸ’» Skills Demonstrated

* Selenium browser automation
* Dynamic userâ€‘agent generation
* Web scraping fundamentals
* Python scripting and virtual environments
* Clean, modular project design
* Git/GitHub workflow
* Portfolioâ€‘ready documentation













## Dev Settings

### Venv

Activate the venv

1. Create the vritual environment

```powershell
python -m venv venv
```

2. Activate the venv

```powershell
.\venv\Scripts\Activate.ps1
```

The (venv) should then appear in the CLI

3. To Deactivate

```powershell
deactivate
```
